---
title: "Data Cleaning"
author: "Manye Dong"
date: "2023-11-16"
output: github_document
---
```{r message=FALSE}
library(tidyverse)
library(readr)
```

```{r message=FALSE}
Student_Weight = read_csv("data/Student Weight.csv")
```

```{r}
Student_Weight  = 
  Student_Weight |>
  janitor::clean_names() |>
  rename('district'='location_code')

Student_Weight$year_reported = sub(".*-", "", Student_Weight$year_reported)

Student_Weight = 
  Student_Weight |>
  mutate(year_reported = as.numeric(Student_Weight$year_reported))
```

```{r message=FALSE}
Student_Weight = Student_Weight |> filter(year_reported==2017 & county!='STATEWIDE (EXCLUDING NYC)') |> select(-region)
Student_Weight
```

```{r message=FALSE}
Demographics_all = read_csv("data/Demographics_all.csv")
```

这里先只选了2019年的，我们可以把2015-2019年的分开成4个dataset（每一年的处理code都复制这个就行），这样每一个dataset的size能小点，不至于load不进来
```{r message=FALSE}
Demographics_all = 
  Demographics_all |> 
  janitor::clean_names() |>
  mutate(district = as.numeric(district)) |>
  filter(year==2017)

Demographics_all
```

```{r message=FALSE}
Enrollments_all = read_csv("data/Enrollments_all.csv")
```

这里也是，先只选了2019年的
```{r}
Enrollments_all = 
  Enrollments_all |>
  janitor::clean_names() |>
  mutate(distrid=as.numeric(distrid)) |>
  rename('district' = 'distrid') |>
  filter(year==2017)

head(Enrollments_all)
```

Join these datasets:

```{r message=FALSE}
result = merge(Student_Weight, Demographics_all, by = "district", all.y = TRUE) |>
  select(-num_free_lunch, -num_reduced_lunch, -num_ell) |>
  drop_na()

result
```

See the unique grade_level:
```{r}
unique(result$grade_level)
```

```{r}
result |> filter(sex=='FEMALE')
```


```{r}
#write.csv(result, file = "result.csv", row.names = FALSE)
```


